{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gRhUhw3_ZLNO"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import io\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aY4r9wNZPq3",
        "outputId": "5be7712e-cc01-4227-8c7c-81c4972a9167"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Scuccorese/food-ingredients-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLJauOPbZW6w",
        "outputId": "60b7669c-0b34-4d47-f376-1456c10116b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing uneccessary data\n",
        "ds = ds.remove_columns([\"subcategory\", \"ingredient\"])\n",
        "ds = ds['train'].train_test_split(test_size=0.2, seed=42)\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lewkPzGBZbG0",
        "outputId": "23d2bf53-5ada-4e6e-b19e-6f66572923b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['category', 'image'],\n",
            "        num_rows: 5340\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['category', 'image'],\n",
            "        num_rows: 1336\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoProcessor\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "\n",
        "# Initialize the processor\n",
        "processor = AutoProcessor.from_pretrained(\"Kaludi/food-category-classification-v2.0\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(ds[\"train\"][\"category\"])\n",
        "\n",
        "# Function to encode labels for a batch of examples\n",
        "def encode_labels(examples):\n",
        "    examples[\"label\"] = label_encoder.transform(examples[\"category\"])\n",
        "    return examples\n",
        "\n",
        "def preprocess_images_and_labels(examples):\n",
        "\n",
        "    # Convert images to RGB format\n",
        "    examples[\"image\"] = [\n",
        "        img.convert(\"RGB\") if img.mode != \"RGB\" else img\n",
        "        for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    examples[\"image\"] = [\n",
        "        img.resize((512, 512)) for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    # Convert images to numpy arrays for processing\n",
        "    examples[\"image\"] = [\n",
        "        np.array(img) for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    inputs = processor(images=examples[\"image\"], return_tensors=\"pt\")\n",
        "\n",
        "    inputs[\"label\"] = examples[\"label\"]\n",
        "    return inputs\n",
        "\n",
        "\n",
        "ds = ds.map(encode_labels, batched=True, batch_size=256)\n",
        "ds = ds.with_transform(preprocess_images_and_labels)\n",
        "\n",
        "# Check the dataset\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj5t4aCHZ6MX",
        "outputId": "b76f88cb-76e0-49db-eb17-db17ee92b81f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['category', 'image', 'label'],\n",
            "        num_rows: 5340\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['category', 'image', 'label'],\n",
            "        num_rows: 1336\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the classifier (output layer)\n",
        "model = AutoModelForImageClassification.from_pretrained(\"Kaludi/food-category-classification-v2.0\", num_labels=12)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classifier layer (final classification head)\n",
        "model.classifier.requires_grad = True"
      ],
      "metadata": {
        "id": "IrTDKX4Lbksi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "if isinstance(model.classifier, nn.Sequential):\n",
        "    in_features = model.classifier[-1].in_features\n",
        "\n",
        "    model.classifier[-1] = nn.Linear(in_features, 12)\n",
        "\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcxxqnumbmTk",
        "outputId": "1788b59d-7224-4a42-c343-6e1b5ce260d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinForImageClassification(\n",
            "  (swin): SwinModel(\n",
            "    (embeddings): SwinEmbeddings(\n",
            "      (patch_embeddings): SwinPatchEmbeddings(\n",
            "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
            "      )\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): SwinEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
            "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (2): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-17): 18 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (3): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=12, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create a DataLoader for the validation dataset\n",
        "val_loader = DataLoader(ds[\"test\"], batch_size=16)"
      ],
      "metadata": {
        "id": "a4x_Ox6SZSko"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "\n",
        "\n",
        "def evaluate_model_batch(model, dataloader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        pixel_values = batch[\"pixel_values\"].to(\"cuda\") if torch.cuda.is_available() else batch[\"pixel_values\"]\n",
        "        labels = torch.tensor(batch[\"label\"]).to(\"cuda\") if torch.cuda.is_available() else torch.tensor(batch[\"label\"])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        # Collect predictions and labels\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "nSpLhAJBaChY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate_model_batch(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FigAjQTFb0q4",
        "outputId": "501835a1-290e-48a0-8e8a-c39e6f5b6a29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-256c2e7155b7>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(batch[\"label\"]).to(\"cuda\") if torch.cuda.is_available() else torch.tensor(batch[\"label\"])\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigN_036LaRe",
        "outputId": "a7f93c5f-4d7a-448b-d310-f69e1fbc79d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.26047904191616766\n"
          ]
        }
      ]
    }
  ]
}